---
title: "MSDS 6306 - Case Study 02"
author: "Huy Hoang Nguyen"
date: "12/05/2019"
output:
  html_document: default
pdf_document: default
---
  
  
## I. Project Description

- DDSAnalytics is an analytics company that specializes in talent management solutions for Fortune 100 companies. Talent management is defined as the iterative process of developing and retaining employees. It may include workforce planning, employee training programs, identifying high-potential employees and reducing/preventing voluntary employee turnover (attrition). To gain a competitive edge over its competition, DDSAnalytics is planning to leverage data science for talent management. The executive leadership has identified predicting employee turnover as its first application of data science for talent management. Before the business green lights the project, they have tasked your data science team to conduct an analysis of existing employee data.   

- Here I will do a data analysis on a given dataset CaseStudy2-data.csv  to identify factors that lead to attrition.  I will identify the top three factors that contribute to turnover (backed up by evidence provided by analysis). There may or may not be a need to create derived attributes/variables/features. The business is also interested in learning about any job role specific trends that may exist in the data set (e.g., “Data Scientists have the highest job satisfaction”). I also provide any other interesting trends and observations from the analysis. The analysis will be backed up by robust experimentation and appropriate visualization. Experiments and analysis  are conducted in R. I will also build a model to predict attrition.   



 


## II. Preparing Steps

### 1. Used Libraries:

```{r libraries, echo=T, results='hide', message=F, warning=F}
library(tidyverse) #The "tidyverse" collects some of the most versatile R packages: ggplot2, dplyr, tidyr, readr, purrr, and tibble. The packages work in harmony to clean, process, model, and visualize data.
library(skimr) #for data summary - so sweet and I like a lot this library
library(mice) #package provides a nice function md.pattern() to get a better understanding of the pattern of missing data
library(VIM) #more helpful visual representation can be obtained using the VIM package for agrr
library(naniar) #https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html (for gg_mis_var) (Missing values)
library(mlbench) #collection of artificial and real-world machine learning benchmark problems, including, e.g., several data sets from the UCI repository. (also has BostonHousing)
library(caret)
library(mlr)
library(tidyverse)
library(ggthemes)
library(gplots)
library(randomForest)
library(corrplot)
library(kableExtra)
library(plotly)
library(GGally) #for ggpairs
library(Boruta) #for Automated EDA later
library(readxl) #read excel
library(e1071) #Naive Bayes


```

### 2. Loading the data: 

```{r data loading}
rawdata0 <- read.csv("CaseStudy2-data.csv")
head(rawdata0)
view(rawdata0) #There are 870 entries, 36 total columns
length(rawdata0) #[1] 36
skim(rawdata0) #so sweet 0- for data summary

rawdata <- rawdata0
```


Then the dataset has 870 observations and 36 variables.

### 3. Checking for missing data:

Actually by skim(rawdata),  we can see there is no missing data in the dataset. However, I will introduce some other codes that can be used to check for missing data as a reference. We only need to run one  code to check for missing data. 

```{r some codes to find missing data}
md.pattern(rawdata)

aggr_plot <- aggr(rawdata, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(rawdata), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

gg_miss_var(rawdata, show_pct = TRUE) + labs(title = "Percent missing of the data") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.y = element_text(angle = 0, vjust = 1))

```


Then the dataset  has no missing data. 

### 4. Dropping unused columns:

We observe by skim() or view() that there are some columns without variation. Then we can drop these columns without affecting our analysis. Observing skim(), we see Over18 has all 870 observations with value Y, EmployeeCount has all 870 observations with value 1, StandardHours has all 870 observations with value 80. In addition, 18 years old is a standard working age and 80 hours/week is high (maybe per 2 weeks - employees receive paycheck per 2 weeks). Then we can drop these three columns.

```{r dropping columns}
drop_columns <- which(apply(rawdata, 2, function(x) (length(unique(x)) == 1)))

cols <- names(drop_columns)
rawdata <- rawdata[,-drop_columns]

#Actually, we can drop manually by another code as  rawdata <- select(rawdata, -c("Over18","EmployeeCount", "StandardHours")) . We will get the same results finally.

skim(rawdata)
```


By  skim(), we can check again the new dataset and all these three columns have been dropped.  

I still want to drop the columns ID and EmployeeNumber. These variables are not related to Salary or Attrition and not usefull for our analysis. They are related to individual identity of each employee. After dropping, I will run skim() to check again the dataset.

```{r dropping more columns}
rawdata <- select(rawdata, -c("ID","EmployeeNumber"))
skim(rawdata)
```

Then now we have 31 columns in the dataset. 

### 5. Pre-processing the data:

I will convert these numeric variables to factor variables.   

```{r}
factorcolumns <- c("JobInvolvement", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "WorkLifeBalance")

rawdata[,factorcolumns] <- lapply(rawdata[,factorcolumns], as.factor)
data0 <- rawdata #data0 - dataset that I use for the analysis
skim(data0)

```


Then now we have 13 factor columns and 18 numeric columns in the dataset.   

In the next part, I will do Exploratory Data Analysis (or EDA). First, I will analyze the dataset in each variable. 






## III. EDA1 - Analysis of each variable and some related variables

First, I will analyze the dataset by analyzing each variable by visualization. We have 870 observations in total (employees).  

I also convert the other variables to factor. I will work on the dataset data1 (<-data0).

```{r}
data1 <- data0

factorcolumns1 <- c("Education", "EnvironmentSatisfaction", "JobLevel", "NumCompaniesWorked", "PercentSalaryHike",  "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "YearsAtCompany", "YearsInCurrentRole",  "YearsSinceLastPromotion", "YearsWithCurrManager")
data1[,factorcolumns1] <- lapply(data1[,factorcolumns1], as.factor)
skim(data1)
```

### 1. Monthly Income:

First, I will take a look at monthly income of employees by the following histogram. 


```{r}
x <- data1$MonthlyIncome 
h<-hist(x, breaks=10, col="steelblue", xlab="Monthly Income", 
        main="Histogram with Normal Curve for Monthly Income") 
xfit<-seq(min(x),max(x),length=40) 
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x)) 
yfit <- yfit*diff(h$mids[1:2])*length(x) 
lines(xfit, yfit, col="red", lwd=2)
```

The following code will show the minimum and maximum salary of 870 employees in the dataset.

```{r range salary}
range(data1$MonthlyIncome)
```


Then the Monthly Income is from 1081 USD to 19999 USD. By the histogram, it is right skewed. The question is that "Will we transform this variable before studying?"   

By the histogram, we see most people have salary in the range [2000,4000] and second range is [4000,6000]. I will divide into 6 groups as follows: 1081 - <2000, 2000 - <4000, 4000 - <6000, 6000 - <10000, and from 10000 - <16000 and 16000 - <20000.  


```{r}

data1$IncomeGroup <- cut(data1$MonthlyIncome, c(0,2000,4000,6000,10000,16000,20000), labels = c("<$2000","$2000-$4000","$4000 - $6000","$6000-$10000","$10000-$16000","$16000-$200000"), include.lowest = TRUE)

```

By the following boxplot,

```{r}
ggplot(data1, aes_string(x = "IncomeGroup", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Income Groups")+ xlab("Income Groups") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 

```   

and the following barplot,  

```{r}

ggplot(data1, aes_string("IncomeGroup")) + geom_bar(fill="steelblue") + xlab ("Monthly Income Group") + ylab("Number of Employees") +ggtitle("Monthly Income vs. Employee Groups")


```


we can see that:
  
  - The salary less than 2000 USD is considered as in lower class.  

- The salary from 2000 USD to 4000 USD is considered as in lower middle class and from 4000 USD to 6000 USD is considered as in  middle class and from 6000 USD to 10000 USD is considered as in upper middle class.  

- The salary from 10000 USD to 16000 USD is considered as in the lower high class and from 16000 USD to 20000 USD is considered as in the high class.  

Now I will study the relationship between Income Group and Attrition. 

```{r}
ggplot(data1, aes_string(x = "IncomeGroup", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Income Group") + ylab("Percent numbers of employees")
```


- Then employees with lower Monthly Income will have more chance to leave the current jobs.


### 2. Attrition: 

I will observe the atrrition data first to see the percentage of employees who left jobs.

```{r Attrition}
stats <- function(df, x) {
  df %>% group_by_at(x) %>% 
    summarise(Count = n(), Proportion = scales::percent(n()/dim(df)[1])) %>% 
    kable() %>% kable_styling(full_width = FALSE)
}

stats(data1, "Attrition")

ggplot(data1, aes_string("Attrition")) + geom_bar(fill="steelblue") + xlab ("Attrition") + ylab("Number of Employees") 
```


- Then there are 140/870 = 16.1 % left jobs (Attrition). 

### 3. Age:

First, I will observe Ages of Employees in the dataset. 

```{r}
summary(data1$Age)
```

- Then, Ages of Employees in this dataset are from 18 to 60 years old.  

We can also use the following code to see the range of ages.

```{r}
range(data1$Age)
```


Now I will take a look at Age variable  by the following histogram. 

```{r}
x <- data1$Age 
h<-hist(x, breaks=10, col="steelblue", xlab="Age", 
        main="Histogram with Normal Curve for Employee Ages") 
xfit<-seq(min(x),max(x),length=40) 
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x)) 
yfit <- yfit*diff(h$mids[1:2])*length(x) 
lines(xfit, yfit, col="red", lwd=2)
```


- Most employees have Ages between 25 to 35. 

We will see the relationship between Age and Attrition  by the following barplot.


```{r}
ggplot(data1, aes_string(x = "Age", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Age") + ylab("Percent numbers of employees")
```


- Employees with Ages between 18 - 21 don't stay in the same job for long time.    
 - People with Age 58-60 don't leave job.   
- People with Age range 30-50 stay with job. They want to build their careers with the same company.    

By the following Scatterplot, we can see the relationship between Age and Monthly Income.  

```{r}
ggplot(data1, aes_string(x = "Age", y = "MonthlyIncome")) + geom_point() + geom_smooth(method="lm")
```


By the histogram, I will divide  Age into 4 groups: 18-25, 25-35, 35-45, 45-60. 

```{r}
data1$AgeGroup <- cut(data1$Age, c(18,25,35,45,60), labels = c("18-25","25-35","35-45","45-60"), include.lowest = TRUE)
```


Now I will study the relationship between Age groups and Attrition.  

```{r}
ggplot(data1, aes_string(x = "AgeGroup", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Age Groups") + ylab("Percentage of employees")
```


- Employees with Age range 18-25 will leave their current jobs more than other groups.  
- Employees with Age range 35-45 will stay with their jobs to build their careers. 

We can also see the relationship between Age Groups and Monthly Income here. 

```{r}
ggplot(data1, aes_string(x = "AgeGroup", y = "MonthlyIncome")) + geom_point() + geom_smooth(method="lm")


ggplot(data1, aes_string(x = "AgeGroup", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Age Groups")+ xlab("Age Groups") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Logically, employees with higher Ages have bigger Income. 


### 4. Business Travel:

```{r}
summary(data1$BusinessTravel)
stats(data1,"BusinessTravel")
```


- Most employees travel rarely (618/870 = 71%).    

Now I will study the relationship between Bussiness Travel and Age.  

```{r}
ggplot(data1, aes_string(x = "AgeGroup", fill = "BusinessTravel")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Age Groups") + ylab("Business Travel")
```


- Then the biggest percentage of frequent travel are for Age Group 25-35.  
- The biggest percenatge of non-travel are for Age Group 35-45. They have stable job and family.   
- The smallest percentage of non-travel are for Age Group 45-60.   

Now we will see the relationship between Business Travel and Attrition.  

```{r}
ggplot(data1, aes_string(x = "BusinessTravel", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Business Travel") + ylab("Attrition")
```


- The most frequent travelers have the highest attrition rates.  

```{r}
ggplot(data1, aes_string(x = "BusinessTravel", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Business Travel Groups")+ xlab("Business Travel") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Non-Travel employee group has the lowest income. 

### 5. Department:

```{r}
summary(data1$Department)
stats(data1, "Department")
```


- 64.6 % employees work in Research and Developpment Department. 
- Only 4.02% employees work in Human Resources.  
- The job market needs more people for R&D or Sales Department. 

```{r}
ggplot(data1, aes_string(x = "Department", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Department") + ylab("Attrition")

```


- The Sales Department has the highest rates in Attrition. 

```{r}
ggplot(data1, aes_string(x = "Department", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Department")+ xlab("Department") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- The Mean Incomes are similar between Department groups.    
- The Median Income is strongly different.  HR Department has the lowest Median Income and Sales Department has the highest Median Income.  




### 6. Distance from Home:  

The following histogram will show us the distance from home of Employees.

```{r}

x <- data1$DistanceFromHome
h<-hist(x, breaks=10, col="steelblue", xlab="Distance from Home", 
        main="Distance from Home vs. Number of Employees") 
xfit<-seq(min(x),max(x),length=40) 
yfit<-dnorm(xfit,mean=mean(x),sd=sd(x)) 
yfit <- yfit*diff(h$mids[1:2])*length(x) 
lines(xfit, yfit, col="red", lwd=2)

```


- Most employees work near home (less than 10 miles). 


```{r}
ggplot(data1, aes_string(x = "DistanceFromHome", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Distance from Home") + ylab("Attrition")

```


- The highest rates in Attrition for the Distance from Home between 21-23 miles. Actually, I don't see strong relationship here. 



### 7. Education:  

```{r}
stats(data1, "Education")

ggplot(data1, aes_string(x = "Education", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Education") + ylab("Attrition")


ggplot(data1, aes_string(x = "Education", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Education")+ xlab("Education") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most employees has the level 3 in Education.    
- Higher level  in  Education has lower rates in Attrition.     
- The Highest level in Education (level 5)   has the Highest Monthly Income.   



### 8. Education Field: 


```{r}
stats(data1, "EducationField")

ggplot(data1, aes_string(x = "EducationField", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Education Field") + ylab("Attrition")


ggplot(data1, aes_string(x = "EducationField", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Education Field")+ xlab("Education Field") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```

- Most employees has formation in Life Science.   
- The lowest median income is in Human Resouce but the highest pay is in HR.   
- The highest median income is in Marketing field.

### 9. Environment Satisfaction:  

```{r}
stats(data1, "EnvironmentSatisfaction")

ggplot(data1, aes_string(x = "EnvironmentSatisfaction", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Environment Satisfaction") + ylab("Attrition")


ggplot(data1, aes_string(x = "EnvironmentSatisfaction", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Environment Satisfaction")+ xlab("Environment Satisfaction") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```

- Most employees are sastified with their jobs.    
- Employees who are less sastified with their jobs have the highest rates in Attrition.     

### 10. Gender:

```{r}
stats(data1, "Gender")

ggplot(data1, aes_string(x = "Gender", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Gender") + ylab("Attrition")


ggplot(data1, aes_string(x = "Gender", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Gender")+ xlab("Gender") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- The rates in Attrition variable are similar between Male and Female in Gender variable.   
- Male group gain less than Female group in term of Median Income. 



### 11. Job Involvement: 


```{r}
stats(data1, "JobInvolvement")

ggplot(data1, aes_string(x = "JobInvolvement", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Job Involvement") + ylab("Attrition")


ggplot(data1, aes_string(x = "JobInvolvement", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Job Involvement")+ xlab("Job Involvement") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Employees with lower job involvement have higher rates in Attrition.  


### 12. Job Level:  


```{r}
stats(data1, "JobLevel")

ggplot(data1, aes_string(x = "JobLevel", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Job Level") + ylab("Attrition")


ggplot(data1, aes_string(x = "JobLevel", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Job Level")+ xlab("Job Level") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Number of employees is lower when their job levels are higher.  
- Employees with the lowest job level (1) have the highest rates in Attrition.  
- The relationship between Job Level and Monthly Income is linear positively.  


### 13. Job Role: 


```{r}
stats(data1, "JobRole")

ggplot(data1, aes_string(x = "JobRole", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Job Role") + ylab("Attrition")


ggplot(data1, aes_string(x = "JobRole", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Job Role")+ xlab("Job Role") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Sales Representatives have the highest rates in Attrition and low pay. 
- Manufacturing Directors and Reseach Directors have the lowest rates in Attrition.  
- Managers and Research Directors have the highest pay and low  rates in Attrition.   


### 14. Job Satisfaction: 


```{r}
stats(data1, "JobSatisfaction")

ggplot(data1, aes_string(x = "JobSatisfaction", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Job Satisfaction") + ylab("Attrition")


ggplot(data1, aes_string(x = "JobSatisfaction", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Job Satisfaction")+ xlab("Job Satisfaction") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most employees are satisfied with their jobs.  
- Those employees with lower job satisfaction level have higher rates in Attrition.   
- Mean and Median Incomes are similar. 



### 15. Marital Status: 


```{r}
stats(data1, "MaritalStatus")

ggplot(data1, aes_string(x = "MaritalStatus", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Marital Status") + ylab("Attrition")


ggplot(data1, aes_string(x = "MaritalStatus", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Marital Status")+ xlab("Marital Status") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most employees are married.  
- Single employees have the highest  attrition and below average pay. 


### 16. Number of Companies Worked:


```{r}
stats(data1, "NumCompaniesWorked")

ggplot(data1, aes_string(x = "NumCompaniesWorked", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Number of Companies Worked") + ylab("Attrition")


ggplot(data1, aes_string(x = "NumCompaniesWorked", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Number of Companies Worked")+ xlab("Number of Companies Worked") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- In the dataset, we can see the number of companies that employees worked is 0. Then it is difficult to understand the concept. I think that the number of companies that employees had worked before starting the job in this company in order to make sense.  
- Who have worked at some companies have higher rates in Attrition.  



### 17. Over Time: 


```{r}
stats(data1, "OverTime")

ggplot(data1, aes_string(x = "OverTime", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Overtime") + ylab("Attrition")


ggplot(data1, aes_string(x = "OverTime", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Overtime")+ xlab("Overtime") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most employees don't work overtime.  
- Who have to work overtime have higher rates in Attrition and lower income.


### 18. Percent Salary Hike:


```{r}
stats(data1, "PercentSalaryHike")

ggplot(data1, aes_string(x = "PercentSalaryHike", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Percent Salary Hike") + ylab("Attrition")


ggplot(data1, aes_string(x = "PercentSalaryHike", y = "MonthlyIncome", fill = x)) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Percent Salary Hike")+ xlab("Percent Salary Hike") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Who have Percent Salary Hike between 22-24% have lower Mean Monthly Income and higher rates in Attrition. 




### 19. Performance Rating:


```{r}
stats(data1, "PerformanceRating")

ggplot(data1, aes_string(x = "PerformanceRating", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Performance Rating") + ylab("Attrition")


ggplot(data1, aes_string(x = "PerformanceRating", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Performance Rating")+ xlab("Performance Rating") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- There are only 2 ratings and the results are similar. 
- I will want to remove this variable because it is a self rating and the results will not affect to our analysis. 


### 20. Relationship Satisfaction:


```{r}
stats(data1, "RelationshipSatisfaction")

ggplot(data1, aes_string(x = "RelationshipSatisfaction", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Relationship Satisfaction") + ylab("Attrition")


ggplot(data1, aes_string(x = "RelationshipSatisfaction", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Relationship Satisfaction")+ xlab("Relationship Satisfaction") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Relationship Satisfaction divides into 4 groups similarly.  
- Employees with low Relationship Satisfaction have high rates in Attrition.  
- Mean and Median Income are similar between groups.  


### 21. Stock Option Level:


```{r}
stats(data1, "StockOptionLevel")

ggplot(data1, aes_string(x = "StockOptionLevel", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Stock Option Level") + ylab("Attrition")


ggplot(data1, aes_string(x = "StockOptionLevel", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Stock Option Level")+ xlab("Stock Option Level") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most  employees fall in Stock Option level 0 or 1.   
- Stock option levels 0 and  3 have the highest rates in Attrition and lowest median incomes.  



### 22. Total Working Years:


```{r}
stats(data1, "TotalWorkingYears")

ggplot(data1, aes_string(x = "TotalWorkingYears", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16) + xlab("Total Working Years") + ylab("Attrition")


ggplot(data1, aes_string(x = "TotalWorkingYears", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Total Working Years")+ xlab("Total Working Years") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Income increases linearly with total working years.  
- Employees have lower total working years have higher rates in Attrition.  
- Especialy, who have 40 years of working have 100% rates in Attrition (retirement?)  
- Employees have 34-39 years of working don't leave jobs, waiting for retirement and full benefits?  


### 23. Training Times Last Year:


```{r}
stats(data1, "TrainingTimesLastYear")

ggplot(data1, aes_string(x = "TrainingTimesLastYear", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Training Times Last Year") + ylab("Attrition")


ggplot(data1, aes_string(x = "TrainingTimesLastYear", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Training Times Last Year")+ xlab("Training Times Last Years") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most Employees had 2 or 3 training times last year. 
- Employees had 0 or 4 training times last year have higher rates in Attrition.  
- Employees had 5 or 6 training times last year have the lowest rates in Attrition.  
- Suprisingly, who had no training time last year have the highest Median and Mean Income.  


### 24. Work Life Balance:


```{r}
stats(data1, "WorkLifeBalance")

ggplot(data1, aes_string(x = "WorkLifeBalance", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Work Life Balance") + ylab("Attrition")


ggplot(data1, aes_string(x = "WorkLifeBalance", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Work Life Balance")+ xlab("Work Life Balance") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Those have bad work life balance then  have higher rates in Attrition and lower income.


### 25.  Years At Company:


```{r}
stats(data1, "YearsAtCompany")

ggplot(data1, aes_string(x = "YearsAtCompany", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("Years At Company") + ylab("Attrition")


ggplot(data1, aes_string(x = "YearsAtCompany", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. Years At Company")+ xlab("Years At Company") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Income increases linearly with Years at Company.  
- Employees have lower Years at Company have higher rates in Attrition.  
- Especialy, who have 40 Years at Company have 100% rates in Attrition (retirement?)  





### 26. Years In Current Role:


```{r}
stats(data1, "YearsInCurrentRole")

ggplot(data1, aes_string(x = "YearsInCurrentRole", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("YearsInCurrentRole") + ylab("Attrition")


ggplot(data1, aes_string(x = "YearsInCurrentRole", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. YearsInCurrentRole")+ xlab("YearsInCurrentRole") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- It's a linear relationship between Monthly Income and Years in Current Role.    
- Who stay more than 15 years in current role don't leave their jobs.  



### 27. Years Since Last Promotion:


```{r}
stats(data1, "YearsSinceLastPromotion")

ggplot(data1, aes_string(x = "YearsSinceLastPromotion", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("YearsSinceLastPromotion") + ylab("Attrition")


ggplot(data1, aes_string(x = "YearsSinceLastPromotion", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Monthly Income vs. YearsSinceLastPromotion")+ xlab("YearsSinceLastPromotion") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- The highest Mean Income is for 12 Years and zero rate in Attrition.


### 28. Years With Current Manager:


```{r}
stats(data1, "YearsWithCurrManager")

ggplot(data1, aes_string(x = "YearsWithCurrManager", fill = "Attrition")) +
    geom_bar(position = "fill") +
    scale_y_continuous(labels = scales::percent) + 
    geom_abline(slope = 0, intercept = .16) + xlab("YearsWithCurrManager") + ylab("Attrition")


ggplot(data1, aes_string(x = "YearsWithCurrManager", y = "MonthlyIncome")) + 
  geom_boxplot(colour = "black", fill = "steelblue")+ ggtitle("Distribution between Monthly Income vs. YearsWithCurrManager")+ xlab("YearsWithCurrManager") + ylab("Monthly Income") + stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
```


- Most employees have 2 years working with the current managers. After that, maybe they move to another companies and promote to next levels?  
- People with 12, 13, 15,16 years with the same managers have zero rate in Attrition.    
- Employees have 14 years with the same managers have the highest Mean and Median Income.  



### 29. Hourly Rate vs Daily Rate vs Monthly Rate vs Monthly Income:


There are 4 similar variables HourlyRate, DailyRate, MonthlyRate, MonthlyIncome. I will see the relationship of these 3 first variables with MonthlyIncome and these 4 variables with Attrition.   

```{r}
ggpairs(data = data1, 
              mapping = aes(color = Attrition),
              columns = c("HourlyRate","DailyRate","MonthlyRate","MonthlyIncome"))
```


- Weak relationship between HourlyRate/DailyRate/MonthlyRate.  
- No meaningful relationship between MonthlyIncome with HourlyRate/DailyRate/MonthlyRate.  
- No meaningful relationship between Attrition with HourlyRate/DailyRate/MonthlyRate.   

Then I will not consider these variables in the future analysis.


### 30. Satisfaction level: 


There are 3 variables related to Satisfaction level: EnvironmentSatisfaction, JobSatisfaction, RelationshipSatisfaction.  

First, I will change these variables from factor to numeric.   


```{r}

numcolumns <- c("EnvironmentSatisfaction", "JobSatisfaction", "RelationshipSatisfaction")
data1[,numcolumns] <- lapply(data1[,numcolumns], as.numeric)

data1$Satisfaction <-   as.factor(round((data1$EnvironmentSatisfaction +data1$JobSatisfaction+ 
                                     data1$RelationshipSatisfaction)/3))


stats(data1, "Satisfaction")

ggplot(data1, aes_string(x = "Satisfaction", fill = "Attrition")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16)


ggplot(data1, aes_string(x = "Satisfaction", fill = "IncomeGroup")) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) + 
  geom_abline(slope = 0, intercept = .16)


```


- Most employees have level 2 or 3 in Satisfaction.  
- Employees with the level 4 in Satisfaction have the lowest rates in Attrition.  
- More employees with the highest Salary and less employees with the lowest Salary have the level 4 in Satisfaction.  



### 32.  Conclusion:

- As the above analyses, I will keep the variable MonthlyIncome and drop 3 variables HourlyRate, DailyRate and MonthlyRate.  
- I will also drop the PerformanceRating variable.  


After the first analyses on each variable,I will create a new dataset as follows.


```{r}
data2 <- select(data0, -c("HourlyRate","DailyRate", "MonthlyRate","PerformanceRating"))
skim(data2)
```






## IV. EDA2 - T-test Analysis

### 1. t-test Analysis on Attrition variable:


```{r Age}
t.Age <- t.test(Age~Attrition, data=data2)
t.Age
t.MonthlyIncome <-  t.test(MonthlyIncome~Attrition, data=data2)
t.MonthlyIncome
t.Education <-  t.test(Education~Attrition, data=data2)
t.Education
t.DistanceFromHome <-  t.test(DistanceFromHome~Attrition, data=data2)
t.DistanceFromHome
t.EnvironmentSatisfaction <-  t.test(EnvironmentSatisfaction~Attrition, data=data2)
t.EnvironmentSatisfaction
t.JobLevel <-  t.test(JobLevel~Attrition, data=data2)
t.JobLevel
t.NumCompaniesWorked  <-  t.test(NumCompaniesWorked ~Attrition, data=data2)
t.NumCompaniesWorked 
t.PercentSalaryHike  <-  t.test(PercentSalaryHike ~Attrition, data=data2)
t.PercentSalaryHike
t.StockOptionLevel  <-  t.test(StockOptionLevel ~Attrition, data=data2)
t.StockOptionLevel
t.TotalWorkingYears  <-  t.test(TotalWorkingYears ~Attrition, data=data2)
t.TotalWorkingYears
t.TrainingTimesLastYear  <-  t.test(TrainingTimesLastYear ~Attrition, data=data2)
t.TrainingTimesLastYear
t.YearsAtCompany  <-  t.test(YearsAtCompany ~Attrition, data=data2)
t.YearsAtCompany
t.YearsInCurrentRole  <-  t.test(YearsInCurrentRole ~Attrition, data=data2)
t.YearsInCurrentRole
t.YearsSinceLastPromotion  <-  t.test(YearsSinceLastPromotion ~Attrition, data=data2)
t.YearsSinceLastPromotion
t.YearsWithCurrManager <-  t.test(YearsWithCurrManager ~Attrition, data=data2)
t.YearsWithCurrManager

```



```{r}
testnames <- c("Age","Monthly Income", "Education",
               "Distance From Home", "Environment Satisfaction", 
               "Job Level", "Number of Companies Worked",
               "Percent Salary Hike", "Stock Option Level",
               "Total Working Years", "Training Times Last Year",
               "Years At Company", "Years In Current Role",
               "Years Since Last Promotion", "Years With Current Manager"
               )
testpval <- c(t.Age$p.value,
              t.MonthlyIncome$p.value,
              t.Education$p.value,
              t.DistanceFromHome$p.value,
              t.EnvironmentSatisfaction$p.value,
              t.JobLevel$p.value,
              t.NumCompaniesWorked$p.value,
              t.PercentSalaryHike$p.value,
              t.StockOptionLevel$p.value,
              t.TotalWorkingYears$p.value,
              t.TrainingTimesLastYear$p.value,
              t.YearsAtCompany$p.value,
              t.YearsInCurrentRole$p.value,
              t.YearsSinceLastPromotion$p.value,
              t.YearsWithCurrManager$p.value
              )
ttestout <- cbind.data.frame(testnames,testpval)
ttestout$testpval <- round(ttestout$testpval,10) 
names(ttestout) <- c("Variable","P-Value")
```


The p-values of t-test analyses related to Attrition variable:


```{r}
ttestout %>% kable()
```



- There are two groups for Attrition variable (Yes and No).   
- At $\alpha$-level of significance = 0.05, if p-value<0.05 then we reject the null hypothesis (There are some evidence to suggest that the mean difference in the selected variable for two groups Yes-No of Attrition variable) and if p-value>0.05 then we fail to reject the null hypothesis (There are not enough evidence to suggest that the mean difference in the selected variable for two groups Yes-No of Attrition variable).  
- By  t-test analysis, we will have some ideas to build our models later.  


### 2. t-test Analysis related to Gender variable:


We now will  use t-test to see the difference of Monthly Income in Job role between Male and Female.  

```{r}
summary(data2$JobRole)
table(data2$Gender,data2$JobRole)
```

```{r filter job role}
data2.Healthcare <- data2 %>% filter(JobRole=="Healthcare Representative")
data2.HR <- data2 %>% filter(JobRole=="Human Resources")
data2.Technician <- data2 %>% filter(JobRole=="Laboratory Technician")
data2.Manager <- data2 %>% filter(JobRole=="Manager")
data2.MDirector <- data2 %>% filter(JobRole=="Manufacturing Director")
data2.RDirector <- data2 %>% filter(JobRole=="Research Director")
data2.Scientist <- data2 %>% filter(JobRole=="Research Scientist")
data2.SExecutive <- data2 %>% filter(JobRole=="Sales Executive")
data2.SRepresentative <- data2 %>% filter(JobRole=="Sales Representative")
```

```{r}
t.jHealthcare <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jHealthcare 

t.jHR <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jHR 

t.jTechnician <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jTechnician 

t.jManager <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jManager

t.jMDirector <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jMDirector

t.jRDirector <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jRDirector

t.jScientist <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jScientist

t.jSExecutive <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jSExecutive

t.jSRepresentative <- t.test(MonthlyIncome ~ Gender, data = data2.Healthcare)
t.jSRepresentative

```



```{r}
testnames1 <- c("Healthcare Representative", "Human Resources", "Laboratory Technician",
               "Manager", "Manufacturing Director", "Research Director", "Research Scientist",
               "Sales Executive", "Sales Representative")
testpval1 <- c(t.jHealthcare$p.value,
              t.jHR$p.value,
              t.jTechnician$p.value,
              t.jManager$p.value,
              t.jMDirector$p.value,
              t.jRDirector$p.value,
              t.jScientist$p.value,
              t.jSExecutive$p.value,
              t.jSRepresentative$p.value
              )
ttestout1 <- cbind.data.frame(testnames1,testpval1)
ttestout1$testpval1 <- round(ttestout1$testpval1,10) 
names(ttestout1) <- c("Variable","P-Value")
```



The p-values of t-test analyses related to Monthly Income in Job role between Male and Female:



```{r}
ttestout1 %>% kable()
```



- There are two groups Male and Female for Gender variable.   
- At $\alpha$-level of significance = 0.05 and  p-value>0.05 then we fail to reject the null hypothesis (There are not enough evidence to suggest that the mean difference in Monthly Income related to Job Role for two groups Male-Female of Gender variable).  
- By  t-test analysis, we will have some ideas to build our models later.  





## V. EDA3 - Numeric variables correlation


In this part, we will have more information related to Monthly Income and Attrition. We will combine our analysis on each variable in the last part.



The following  table will show us the correlations between numeric variables. 

```{r}

correlator  <-  function(df){
 df %>%
    keep(is.numeric) %>%
    tidyr::drop_na() %>%
    cor %>%
    corrplot("upper", addCoef.col = "white", number.digits = 2,
             number.cex = 0.5, method="square",
             order="hclust", 
             tl.srt=50, tl.cex = 0.5)
}
correlator(data2)

#Actually, we can remove tidyr::drop_na() %>%  because there is no missing data in this dataset

#We can write the same code directly without using function as follows
#data2 %>% keep(is.numeric) %>% na.omit %>% cor %>% corrplot("upper", addCoef.col = "white", number.digits = 2, number.cex = 0.5, method="square", order="hclust", tl.srt=50, tl.cex = 0.5)

#We can remove na.omit %>% because there is no missing data in this dataset

```

### 1. Analysis on Monthly Income

By this correlation table, we see

Relationship       |	MonthlyIncome
------------------ | -------------
JobLevel           | 	0.95
TotalWorkingYears  |	0.78
YearsAtCompany	   |  0.49
Age                 |  0.48
YearsInCurrentRole  |  0.36
YearsWithCurrManager  |  0.33
YearsSinceLastPromotion  |  0.32



Then by some analyses, we can see that Monthly Income have a strong correlation with Job Level. Month Income, Total Working Years and Job Level are correlated strongly. These correlations are logical.


### 2. Analysis on Job Level

We have

Relationship  |  JobLevel
--------------|----------
MonthlyIncome  |  0.95  
TotalWorkingYears  | 0.78  
YearsAtCompany  |  0.52  
Age  | 0.48
YearsinCurrentRole  |  0.39  
YearsWithCurrManager  |  0.37  
YearsSinceLastPromotion  |  0.33  


Then by some analyses, we can see that Job Level have a strong correlation with Monthly Income. Month Income, Total Working Years and Job Level are correlated strongly. These correlations are logical.  

### 3. Analysis on Atrrition  

By **EDA1 - Analysis on each variable** and by the correlation plot, we can see that some  numerical variables have relationship with Attrition here (MonthlyIncome ~ TotalWorkingYears, JobLevel ~ TotalWorkingYears, YearsAtCompany ~ YearsinCurrentRole, YearsWithCurrManager  ~ YearsinCurrentRole, YearsWithCurrManager  ~ YearsAtCompany). 

We will do another analysis in the next part to decide a good model.  





## VI. EDA4 - Automated EDA

### 1. Analysis on Monthly Income


Now I will use Automated EDA for Feature Selection. I use the library Boruta here to select important variables related to MonthlyIncome variable. 
(http://r-statistics.co/Variable-Selection-and-Importance-With-R.html)  




```{r, echo=T, message=F, warning=F}
boruta_output <- Boruta(MonthlyIncome ~ ., data=data2, doTrace=2)
boruta_signif <- names(boruta_output$finalDecision[boruta_output$finalDecision %in% c("Confirmed", "Tentative")])  # collect Confirmed and Tentative variables
print(boruta_signif)  # significant variables
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
```

 
Then after running this code, I have 14 important variables as follows: Age,              Attrition, BusinessTravel, Department, Education, JobLevel, JobRole, NumCompaniesWorked, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager.   


### 2. Analysis on Attrition

Similarly, I will run the following code 


```{r, echo=T, message=F, warning=F}
boruta_output <- Boruta(Attrition ~ ., data=rawdata0, doTrace=2)
boruta_signif <- names(boruta_output$finalDecision[boruta_output$finalDecision %in% c("Confirmed", "Tentative")])  # collect Confirmed and Tentative variables
print(boruta_signif)  # significant variables
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
```


Then I will use important variable to build a model later: Age, Department,  EnvironmentSatisfaction,  JobInvolvement,  JobLevel, JobRole,  JobSatisfaction, MaritalStatus,  MonthlyIncome, NumCompaniesWorked,  OverTime, StockOptionLevel,  TotalWorkingYears, WorkLifeBalance, YearsAtCompany, YearsInCurrentRole, YearsWithCurrManager.  





## VII. EDA5 - Multiple Linear Regression and Validation for Salary 


Here we will use our EDA4 to build model for Monthly Income.


### 1. Build a Model   


I will build a multiple linear regression on Monthly Income related to 14 important variables in the last part.



```{r}

set.seed(100)
data3 <- select(rawdata, "MonthlyIncome", "Age", "Attrition", "BusinessTravel", "Department", "Education", "JobLevel", "JobRole", "NumCompaniesWorked", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager")
splitPerc1 = 0.8
trainIndices1 = sample(1:dim(data3)[1],round(splitPerc1 * dim(data3)[1]))
train1 = data3[trainIndices1,]
test1 = data3[-trainIndices1,]
lm1 = lm(MonthlyIncome ~ ., data = train1)
summary(lm1)
pred1 = predict(lm1, test1)
RMSE = sqrt(mean((test1$MonthlyIncome - pred1)^2))
RMSE


```


Then RMSE is around $1031.816.   



### 2. Validation Requirement for Salary


Here I will use the file CaseStudy2CompSet No Salary.xlsx and create new dataframe case2nosalary1  with the same variables as the dataframe data3 in the last step (Build a Model) (without MonthlyIncome variable).


```{r}
case2nosalary <- read_excel("CaseStudy2CompSet No Salary.xlsx")
case2nosalary1 <- select(case2nosalary, "Age", "Attrition", "BusinessTravel", "Department", "Education", "JobLevel", "JobRole", "NumCompaniesWorked", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsSinceLastPromotion", "YearsWithCurrManager")
```


Now I will use  the model built in the last step to predicting the salary for the file CaseStudy2CompSet No Salary.xlsx. 



```{r}

lm2 = lm(MonthlyIncome ~ ., data = data3)
pred2 = predict(lm2, case2nosalary1)


MonthlyIncome = pred2
MonthlyIncome = as.data.frame(MonthlyIncome)

case2nosalary2 = cbind(case2nosalary, MonthlyIncome)


write.csv(case2nosalary2, "Case2PredictionsNguyenSalary.csv", row.names = FALSE)

case2nosalary3 <- read.csv("Case2PredictionsNguyenSalary.csv", header = T)

head(case2nosalary3)

```

Later, I will upload the preditecd file Case2PredictionsNguyenSalary.csv for Salary into github. 




## VIII. EDA6 - Naive Bayes classifiers and Validation for Attrition


Here I will use our EDA4 to build model for Attrition. I will use these vatiables: Age, Department,  EnvironmentSatisfaction,  JobInvolvement,  JobLevel, JobRole,  JobSatisfaction, MaritalStatus,  MonthlyIncome, NumCompaniesWorked,  OverTime, StockOptionLevel,  TotalWorkingYears, WorkLifeBalance, YearsAtCompany, YearsInCurrentRole, YearsWithCurrManager. 

### 1. Build a Model   


I will use Naive Bayes classifiers to build a model here.


```{r}


data4 <- select(rawdata, "Attrition", "Age", "Department",  "EnvironmentSatisfaction",  "JobInvolvement",  "JobLevel", "JobRole",  "JobSatisfaction", "MaritalStatus",  "MonthlyIncome", "NumCompaniesWorked",  "OverTime", "StockOptionLevel",  "TotalWorkingYears", "WorkLifeBalance", "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager")


set.seed(10000)
splitPercNB1 = 0.8
trainIndicesNB1 = sample(1:dim(data4)[1],round(splitPercNB1 * dim(data4)[1]))
trainNB1 = data4[trainIndicesNB1,]
testNB1 = data4[-trainIndicesNB1,]

NB1 <- naiveBayes(Attrition~.,data = trainNB1,laplace = -1)
predNB1 = predict(NB1, testNB1)

table(as.factor(testNB1$Attrition),predNB1)

#Confusion Matrix
confusion.Matrix = confusionMatrix(predNB1,as.factor(testNB1$Attrition))
confusion.Matrix
Sensitivity = confusion.Matrix$byClass['Sensitivity']
Specificity = confusion.Matrix$byClass['Specificity']
Accuracy = confusion.Matrix$overall['Accuracy']

Accuracy
Sensitivity
Specificity







```

### 2. Validation Requirement for Attrition  


Here I will use the file CaseStudy2CompSet No Attrition.csv and create new dataframe case2noattrition1  with the same variables as the dataframe data4 in the last step (Build a Model) (without Attrition variable).


```{r}
case2noattrition <- read.csv("CaseStudy2CompSet No Attrition.csv")
case2noattrition1 <- select(case2noattrition, "Age", "Department",  "EnvironmentSatisfaction",  "JobInvolvement",  "JobLevel", "JobRole",  "JobSatisfaction", "MaritalStatus",  "MonthlyIncome", "NumCompaniesWorked",  "OverTime", "StockOptionLevel",  "TotalWorkingYears", "WorkLifeBalance", "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager")
```


Now I will use  the model built in the last step to predicting Attrition for the file CaseStudy2CompSet No Attrition.csv. 



```{r}


set.seed(10000)

NB2 <- naiveBayes(Attrition~.,data = data4,laplace = -1)
predNB2 = predict(NB2, case2noattrition1)


Attrition = predNB2
Attrition = as.data.frame(Attrition)
case2noattrition2 = cbind(case2noattrition,Attrition)

write.csv(case2noattrition2,"Case2PredictionsNguyenAttrition.csv", row.names = FALSE)

case2noattrition3 <- read.csv("Case2PredictionsNguyenAttrition.csv", header = T)

head(case2noattrition3)
```




Later, I will upload the preditecd file Case2PredictionsNguyenAttrition.csv for Salary into github. 


## Conclusion

In this analysis, we have seen the entire process from importing the dataset and pre-processing data, exploring data analysis with different levels (each variales, t-test, numerical variable correlation, automated EDA) and then building models using different methods (multiple linear regression, Naive Bayes classifiers). Finally, we predicted and validated the two datasets for Salary and Attrition.

