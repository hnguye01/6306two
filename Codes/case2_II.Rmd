---
title: "MSDS 6306 - Case Study 02"
author: "Huy Hoang Nguyen"
date: "12/05/2019"
output:
  html_document: default
pdf_document: default
---
  


## II. Preparing Steps

### 1. Used Libraries:

```{r libraries, echo=T, results='hide', message=F, warning=F}
library(tidyverse) #The "tidyverse" collects some of the most versatile R packages: ggplot2, dplyr, tidyr, readr, purrr, and tibble. The packages work in harmony to clean, process, model, and visualize data.
library(skimr) #for data summary - so sweet and I like a lot this library
library(mice) #package provides a nice function md.pattern() to get a better understanding of the pattern of missing data
library(VIM) #more helpful visual representation can be obtained using the VIM package for agrr
library(naniar) #https://cran.r-project.org/web/packages/naniar/vignettes/getting-started-w-naniar.html (for gg_mis_var) (Missing values)
library(mlbench) #collection of artificial and real-world machine learning benchmark problems, including, e.g., several data sets from the UCI repository. (also has BostonHousing)
library(caret)
library(mlr)
library(tidyverse)
library(ggthemes)
library(gplots)
library(randomForest)
library(corrplot)
library(kableExtra)
library(plotly)
library(GGally) #for ggpairs
library(Boruta) #for Automated EDA later
library(readxl) #read excel
library(e1071) #Naive Bayes


```

### 2. Loading the data: 

```{r data loading}
rawdata0 <- read.csv("CaseStudy2-data.csv")
head(rawdata0)
view(rawdata0) #There are 870 entries, 36 total columns
length(rawdata0) #[1] 36
skim(rawdata0) #so sweet 0- for data summary

rawdata <- rawdata0
```


Then the dataset has 870 observations and 36 variables.

### 3. Checking for missing data:

Actually by skim(rawdata),  we can see there is no missing data in the dataset. However, I will introduce some other codes that can be used to check for missing data as a reference. We only need to run one  code to check for missing data. 

```{r some codes to find missing data}
md.pattern(rawdata)

aggr_plot <- aggr(rawdata, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(rawdata), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

gg_miss_var(rawdata, show_pct = TRUE) + labs(title = "Percent missing of the data") + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), axis.title.y = element_text(angle = 0, vjust = 1))

```


Then the dataset  has no missing data. 

### 4. Dropping unused columns:

We observe by skim() or view() that there are some columns without variation. Then we can drop these columns without affecting our analysis. Observing skim(), we see Over18 has all 870 observations with value Y, EmployeeCount has all 870 observations with value 1, StandardHours has all 870 observations with value 80. In addition, 18 years old is a standard working age and 80 hours/week is high (maybe per 2 weeks - employees receive paycheck per 2 weeks). Then we can drop these three columns.

```{r dropping columns}
drop_columns <- which(apply(rawdata, 2, function(x) (length(unique(x)) == 1)))

cols <- names(drop_columns)
rawdata <- rawdata[,-drop_columns]

#Actually, we can drop manually by another code as  rawdata <- select(rawdata, -c("Over18","EmployeeCount", "StandardHours")) . We will get the same results finally.

skim(rawdata)
```


By  skim(), we can check again the new dataset and all these three columns have been dropped.  

I still want to drop the columns ID and EmployeeNumber. These variables are not related to Salary or Attrition and not usefull for our analysis. They are related to individual identity of each employee. After dropping, I will run skim() to check again the dataset.

```{r dropping more columns}
rawdata <- select(rawdata, -c("ID","EmployeeNumber"))
skim(rawdata)
```

Then now we have 31 columns in the dataset. 

### 5. Pre-processing the data:

I will convert these numeric variables to factor variables.   

```{r}
factorcolumns <- c("JobInvolvement", "JobSatisfaction", "PerformanceRating", "RelationshipSatisfaction", "WorkLifeBalance")

rawdata[,factorcolumns] <- lapply(rawdata[,factorcolumns], as.factor)
data0 <- rawdata #data0 - dataset that I use for the analysis
skim(data0)

```


Then now we have 13 factor columns and 18 numeric columns in the dataset.   

In the next part, I will do Exploratory Data Analysis (or EDA). First, I will analyze the dataset in each variable. 

